{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2407444/2014934985.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sae_weights = torch.load(sae_path)\n",
      "/tmp/ipykernel_2407444/2014934985.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiffusionTransformerLowdimPolicy(\n",
       "  (model): TransformerForDiffusion(\n",
       "    (input_emb): Linear(in_features=2, out_features=256, bias=True)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (time_emb): SinusoidalPosEmb()\n",
       "    (cond_obs_emb): Linear(in_features=20, out_features=256, bias=True)\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (1): Mish()\n",
       "      (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.3, inplace=False)\n",
       "          (dropout2): Dropout(p=0.3, inplace=False)\n",
       "          (dropout3): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       "  (mask_generator): LowdimMaskGenerator()\n",
       "  (normalizer): LinearNormalizer(\n",
       "    (params_dict): ParameterDict(\n",
       "        (obs): Object of type: ParameterDict\n",
       "        (action): Object of type: ParameterDict\n",
       "      (obs): ParameterDict(\n",
       "          (offset): Parameter containing: [torch.cuda.FloatTensor of size 20 (cuda:0)]\n",
       "          (scale): Parameter containing: [torch.cuda.FloatTensor of size 20 (cuda:0)]\n",
       "          (input_stats): Object of type: ParameterDict\n",
       "        (input_stats): ParameterDict(\n",
       "            (max): Parameter containing: [torch.cuda.FloatTensor of size 20 (cuda:0)]\n",
       "            (mean): Parameter containing: [torch.cuda.FloatTensor of size 20 (cuda:0)]\n",
       "            (min): Parameter containing: [torch.cuda.FloatTensor of size 20 (cuda:0)]\n",
       "            (std): Parameter containing: [torch.cuda.FloatTensor of size 20 (cuda:0)]\n",
       "        )\n",
       "      )\n",
       "      (action): ParameterDict(\n",
       "          (offset): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "          (scale): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "          (input_stats): Object of type: ParameterDict\n",
       "        (input_stats): ParameterDict(\n",
       "            (max): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "            (mean): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "            (min): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "            (std): Parameter containing: [torch.cuda.FloatTensor of size 2 (cuda:0)]\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/work/pi_hzhang2_umass_edu/jnainani_umass_edu/diffusion_policy_interp/\")\n",
    "from sae.sae_model import SparseAutoencoder\n",
    "import torch \n",
    "import pandas as pd \n",
    "from tqdm.auto import tqdm\n",
    "from skvideo.io import vwrite\n",
    "from IPython.display import Video\n",
    "from diffusion_policy.policy.diffusion_transformer_lowdim_policy import DiffusionTransformerLowdimPolicy\n",
    "from diffusion_policy.model.diffusion.transformer_for_diffusion import TransformerForDiffusion\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import random\n",
    "from diffusion_policy.env.pusht.pusht_keypoints_env import PushTKeypointsEnv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "seed1_acts = pd.read_csv(\"data/activations_summary.csv\")\n",
    "seed2_acts = pd.read_csv(\"data/activations_summary_2.csv\")\n",
    "\n",
    "sae_path = \"sae/results_layer4_dim2048_k64_auxk64_dead200/checkpoints/last.ckpt\"\n",
    "sae_weights = torch.load(sae_path)\n",
    "ckpt = {}\n",
    "for k in sae_weights['state_dict'].keys():\n",
    "    if k.startswith('sae_model.'):\n",
    "        ckpt[k.split(\".\")[1]] = sae_weights['state_dict'][k]\n",
    "sae = SparseAutoencoder(256, 2048, 64, 64, 32, 200)\n",
    "sae.load_state_dict(ckpt)\n",
    "sae.to(device)\n",
    "\n",
    "ckpt_path = \"/work/pi_hzhang2_umass_edu/jnainani_umass_edu/Interp4Robotics/diffusionInterp/data/experiments/low_dim/pusht/diffusion_policy_transformer/train_2/checkpoints/latest.ckpt\"\n",
    "state_dict = torch.load(ckpt_path, map_location=device)\n",
    "config = state_dict['cfg']\n",
    "model_config = config['policy']['model']\n",
    "model_config = {k: v for k, v in model_config.items() if not k.startswith('_target_')}\n",
    "model = TransformerForDiffusion(**model_config)\n",
    "noise_scheduler_config = config['policy']['noise_scheduler']\n",
    "noise_scheduler = DDPMScheduler(**noise_scheduler_config)\n",
    "policy_params = {\n",
    "    'model': model,\n",
    "    'noise_scheduler': noise_scheduler,\n",
    "    'horizon': config['policy']['horizon'],\n",
    "    'obs_dim': config['policy']['obs_dim'],\n",
    "    'action_dim': config['policy']['action_dim'],\n",
    "    'n_action_steps': config['policy']['n_action_steps'],\n",
    "    'n_obs_steps': config['policy']['n_obs_steps'],\n",
    "    'num_inference_steps': config['policy'].get('num_inference_steps', None),\n",
    "    'obs_as_cond': config['policy'].get('obs_as_cond', False),\n",
    "    'pred_action_steps_only': config['policy'].get('pred_action_steps_only', False),\n",
    "}\n",
    "policy = DiffusionTransformerLowdimPolicy(**policy_params)\n",
    "policy.load_state_dict(state_dict['state_dicts']['model'])\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seed = 92400 # int(seed)\n",
    "# target_step = int(step)\n",
    "obs_horizon = 2\n",
    "# target_timestep = int(timestep)\n",
    "env = PushTKeypointsEnv()\n",
    "env.seed(target_seed)\n",
    "np.random.seed(target_seed)\n",
    "torch.manual_seed(target_seed)\n",
    "obs = env.reset()\n",
    "imgs = []  #\n",
    "obs_deque = collections.deque([obs[:20]] * obs_horizon, maxlen=obs_horizon)\n",
    "done = False\n",
    "max_steps = 200\n",
    "step_idx = 0\n",
    "rewards = []\n",
    "policy.to('cuda')\n",
    "# inference_inputs = {}\n",
    "with tqdm(total=max_steps, desc=f\"Seed {target_seed} Eval\") as pbar:\n",
    "    while not done:\n",
    "        B = 1\n",
    "        obs_seq = np.stack(obs_deque)\n",
    "        nobs = torch.from_numpy(obs_seq).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Normalization and action inference logic from your code\n",
    "            nobs = policy.normalizer['obs'].normalize(nobs)\n",
    "            B, _, Do = nobs.shape\n",
    "            To = policy.n_obs_steps\n",
    "            T = policy.horizon\n",
    "            Da = policy.action_dim\n",
    "            device = policy.device\n",
    "            dtype = policy.dtype\n",
    "            cond = nobs[:, :To]\n",
    "\n",
    "            shape = (B, T, Da)\n",
    "            if policy.pred_action_steps_only:\n",
    "                shape = (B, policy.n_action_steps, Da)\n",
    "            cond_data = torch.zeros(size=shape, device=device, dtype=dtype)\n",
    "            cond_mask = torch.zeros_like(cond_data, dtype=torch.bool)\n",
    "\n",
    "            generator = None\n",
    "            trajectory = torch.randn(\n",
    "                size=cond_data.shape, \n",
    "                dtype=cond_data.dtype,\n",
    "                device=cond_data.device,\n",
    "                generator=generator)\n",
    "    \n",
    "            policy.noise_scheduler.set_timesteps(policy.num_inference_steps)\n",
    "\n",
    "            \n",
    "            for t in policy.noise_scheduler.timesteps:\n",
    "                trajectory[cond_mask] = cond_data[cond_mask]\n",
    "\n",
    "                model_output = policy.model(trajectory, t, cond)\n",
    "\n",
    "                trajectory = policy.noise_scheduler.step(\n",
    "                    model_output, t, trajectory, \n",
    "                    generator=generator,\n",
    "                    **policy.kwargs\n",
    "                ).prev_sample\n",
    "\n",
    "            trajectory[cond_mask] = cond_data[cond_mask]\n",
    "            naction_pred = trajectory[..., :Da]\n",
    "            action_pred = policy.normalizer['action'].unnormalize(naction_pred)\n",
    "\n",
    "            start = To - 1\n",
    "            end = start + policy.n_action_steps\n",
    "            action = action_pred[:, start:end]\n",
    "\n",
    "            # inference_inputs[step_idx] = []\n",
    "            # if step_idx == target_step:\n",
    "            #     target_obs = cond.clone().cpu().numpy()\n",
    "            #     target_step_image = env.render(mode='rgb_array')\n",
    "            #     target_action = action.clone().cpu().numpy()\n",
    "                # print(f\"Step {step_idx} Image\")\n",
    "\n",
    "        naction = action.detach().to('cpu').numpy()\n",
    "        action = naction[0]\n",
    "\n",
    "        for i in range(len(action)):\n",
    "            obs, reward, done, _ = env.step(action[i])\n",
    "            obs_deque.append(obs[:20])\n",
    "            rewards.append(reward)\n",
    "            imgs.append(env.render(mode='rgb_array'))\n",
    "            step_idx += 1\n",
    "            pbar.update(1)\n",
    "            if step_idx > max_steps:\n",
    "                done = True\n",
    "            if done:\n",
    "                print(f\"Reward for {target_seed}: \", max(rewards))\n",
    "                break\n",
    "\n",
    "from IPython.display import Video\n",
    "vwrite(f'out/lowdim_seed{target_seed}_og.mp4', imgs)\n",
    "Video(f'out/lowdim_seed{target_seed}_og.mp4', embed=True, width=256, height=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -idia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -idia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (8.0.4)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipywidgets) (4.0.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipywidgets) (6.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
      "Requirement already satisfied: pyzmq>=20 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (26.0.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: packaging in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: psutil in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: backcall in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.0.4)\n",
      "Requirement already satisfied: pickleshare in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: asttokens in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -idia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -idia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -idia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -idia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seed = 92400\n",
    "latent_idx = 922\n",
    "steering_coefficient = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnainani_umass_edu/.conda/envs/finetuning/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b91b7025a54d7c94d71aa0f84eb561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Value:', max=15, min=-15, step=0, style=SliderStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a slider\n",
    "slider = widgets.IntSlider(\n",
    "    value=0,     # Default value\n",
    "    min=-15,        # Minimum value\n",
    "    max=15,      # Maximum value\n",
    "    step=0.5,       # Step size\n",
    "    description='Value:',\n",
    "    style={'description_width': 'initial'}  # Adjust label width if needed\n",
    ")\n",
    "\n",
    "# Display the slider\n",
    "display(slider)\n",
    "# global steering_coefficient\n",
    "# Access the slider value\n",
    "def on_value_change(change):\n",
    "    return change\n",
    "\n",
    "# Observe changes\n",
    "steering_coefficient = slider.observe(on_value_change, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.seed(target_seed)\n",
    "np.random.seed(target_seed)\n",
    "torch.manual_seed(target_seed)\n",
    "obs = env.reset()\n",
    "imgs = []  #\n",
    "obs_deque = collections.deque([obs[:20]] * obs_horizon, maxlen=obs_horizon)\n",
    "done = False\n",
    "max_steps = 200\n",
    "step_idx = 0\n",
    "rewards = []\n",
    "policy.to('cuda')\n",
    "\n",
    "def steer_latent(layer_num, sae, steering_coefficient, latent_idx):\n",
    "    def hook(module, input, output):\n",
    "        output = output + steering_coefficient * sae.w_dec[latent_idx]\n",
    "        return output\n",
    "    return hook\n",
    "layer_num = 4\n",
    "handle = policy.model.decoder.layers[layer_num].register_forward_hook(steer_latent(layer_num, sae, steering_coefficient, latent_idx))\n",
    "try: \n",
    "    with tqdm(total=max_steps, desc=f\"Seed {target_seed} Eval\") as pbar:\n",
    "        while not done:\n",
    "            B = 1\n",
    "            obs_seq = np.stack(obs_deque)\n",
    "            nobs = torch.from_numpy(obs_seq).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nobs = policy.normalizer['obs'].normalize(nobs)\n",
    "                B, _, Do = nobs.shape\n",
    "                To = policy.n_obs_steps\n",
    "                T = policy.horizon\n",
    "                Da = policy.action_dim\n",
    "                device = policy.device\n",
    "                dtype = policy.dtype\n",
    "                cond = nobs[:, :To]\n",
    "\n",
    "                shape = (B, T, Da)\n",
    "                if policy.pred_action_steps_only:\n",
    "                    shape = (B, policy.n_action_steps, Da)\n",
    "                cond_data = torch.zeros(size=shape, device=device, dtype=dtype)\n",
    "                cond_mask = torch.zeros_like(cond_data, dtype=torch.bool)\n",
    "\n",
    "                generator = None\n",
    "                trajectory = torch.randn(\n",
    "                    size=cond_data.shape, \n",
    "                    dtype=cond_data.dtype,\n",
    "                    device=cond_data.device,\n",
    "                    generator=generator)\n",
    "        \n",
    "                policy.noise_scheduler.set_timesteps(policy.num_inference_steps)\n",
    "\n",
    "                for t in policy.noise_scheduler.timesteps:\n",
    "                    trajectory[cond_mask] = cond_data[cond_mask]\n",
    "                    model_output = policy.model(trajectory, t, cond)\n",
    "                    trajectory = policy.noise_scheduler.step(\n",
    "                        model_output, t, trajectory, \n",
    "                        generator=generator,\n",
    "                        **policy.kwargs\n",
    "                    ).prev_sample\n",
    "\n",
    "                trajectory[cond_mask] = cond_data[cond_mask]\n",
    "                naction_pred = trajectory[..., :Da]\n",
    "                action_pred = policy.normalizer['action'].unnormalize(naction_pred)\n",
    "\n",
    "                start = To - 1\n",
    "                end = start + policy.n_action_steps\n",
    "                action = action_pred[:, start:end]\n",
    "\n",
    "            naction = action.detach().to('cpu').numpy()\n",
    "            action = naction[0]\n",
    "\n",
    "            for i in range(len(action)):\n",
    "                obs, reward, done, _ = env.step(action[i])\n",
    "                obs_deque.append(obs[:20])\n",
    "                rewards.append(reward)\n",
    "                imgs.append(env.render(mode='rgb_array'))\n",
    "                step_idx += 1\n",
    "                pbar.update(1)\n",
    "                if step_idx > max_steps:\n",
    "                    done = True\n",
    "                if done:\n",
    "                    print(f\"Reward for {target_seed}: \", max(rewards))\n",
    "                    break\n",
    "finally:\n",
    "    # Remove hooks\n",
    "    handle.remove()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "from IPython.display import Video\n",
    "vwrite(f'out/lowdim_seed{target_seed}_f{latent_idx}_steer{steering_coefficient}.mp4', imgs)\n",
    "Video(f'out/lowdim_seed{target_seed}_f{latent_idx}_steer{steering_coefficient}.mp4', embed=True, width=256, height=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
